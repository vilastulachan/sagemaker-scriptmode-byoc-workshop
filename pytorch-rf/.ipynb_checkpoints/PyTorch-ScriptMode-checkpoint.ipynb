{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Bring your own Script workshop\n",
    "\n",
    "Goal: In this notebook we will go through and run a PyTorch model to classify the junctions as priority, signal and roundabout as seen in data prep.\n",
    "\n",
    "The outline of this notebook is\n",
    "\n",
    "1. Update to the latest SageMaker version & import libraries\n",
    "2. Download data, setup buckets and Understanding the data\n",
    "3. Setup estimator and review the AWS provided PyTorch container and provide our script to it.\n",
    "4. Run training.\n",
    "5. Deploy model to end point.\n",
    "6. Test using an image in couple of possible ways\n",
    "7. Clean up - delete the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "### 1. Update Sagemaker so we can access the latest containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip\n",
    "!pip install -U sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will import the libraries and set up the initial variables we will be using in this lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "ON_SAGEMAKER_NOTEBOOK = True\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "if ON_SAGEMAKER_NOTEBOOK:\n",
    "    role = sagemaker.get_execution_role()\n",
    "else:\n",
    "    role = \"[YOUR ROLE]\"\n",
    "\n",
    "import boto3\n",
    "client = boto3.client('sagemaker-runtime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2. Next Download the data and setup bucket\n",
    "In the cell below, replace **\"your-unique-bucket-name\"** with the name of bucket you created in the data-prep notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give a globally unique bucket name\n",
    "my_bucket = \"2021-11-15-pvt-1234\"\n",
    "!aws s3 mb 's3://'$my_bucket --region us-west-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the training bucket  \n",
    "training_data_uri=\"s3://{}\".format(my_bucket)\n",
    "training_data_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the copy in the directory\n",
    "#!aws s3 ls s3://public-rk/junctions-data.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the copy in the directory\n",
    "# xN'R Download the data \n",
    "#!aws s3 cp s3://public-rk/junctions-data.tar.gz ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncompress the data\n",
    "!tar -xzf junctions-data.tar.gz . --no-same-owner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the data to your bucket\n",
    "!aws s3 sync ./data/ 's3://'$my_bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's view the data - images\n",
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "f, axs = plt.subplots(1,3,figsize=(15,15))\n",
    "img1 = mpimg.imread('./data/train/Priority/12481.png')\n",
    "img2 = mpimg.imread('./data/train/Roundabout/53408.png')\n",
    "img3 = mpimg.imread('./data/train/Signal/27258.png')\n",
    "\n",
    "axs[0].imshow(img1)\n",
    "axs[0].set_title(\"Priority\")\n",
    "axs[1].imshow(img2)\n",
    "axs[1].set_title(\"Roundabout\")\n",
    "axs[2].imshow(img3)\n",
    "axs[2].set_title(\"Signal\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### 3. PyTorch Estimator & review code\n",
    "\n",
    "Use AWS provided open source containers, these containers can be extended by starting with the image provided by AWS and the add additional installs in dockerfile\n",
    "\n",
    "or you can use requirements.txt in source_dir to install additional libraries.\n",
    "\n",
    "Below code is for PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = PyTorch(entry_point='ptModelCode.py',\n",
    "                    role=role,\n",
    "                    framework_version='1.8',\n",
    "                    instance_count=1,\n",
    "                    instance_type='ml.p2.xlarge',\n",
    "                    py_version='py3',\n",
    "                    # available hyperparameters: emsize, nhid, nlayers, lr, clip, epochs, batch_size,\n",
    "                    #                            bptt, dropout, tied, seed, log_interval\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m, \u001b[04m\u001b[36mtorchvision\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36moptim\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m lr_scheduler\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mcollections\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m defaultdict\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m nn, optim\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorchvision\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mtransforms\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mT\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorchvision\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdatasets\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m ImageFolder\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdata\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m DataLoader\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorchvision\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m models\n",
      "\n",
      "RANDOM_SEED = \u001b[34m42\u001b[39;49;00m\n",
      "np.random.seed(RANDOM_SEED)\n",
      "torch.manual_seed(RANDOM_SEED)\n",
      "\n",
      "device = torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "n_classes=\u001b[34m3\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mcreate_model\u001b[39;49;00m(n_classes):\n",
      "    model = models.resnet34(pretrained=\u001b[34mTrue\u001b[39;49;00m)\n",
      "\n",
      "    n_features = model.fc.in_features\n",
      "    model.fc = nn.Linear(n_features, n_classes)\n",
      "\n",
      "    \u001b[34mreturn\u001b[39;49;00m model.to(device)\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtrain_epoch\u001b[39;49;00m(\n",
      "        model,\n",
      "        data_loader,\n",
      "        loss_fn,\n",
      "        optimizer,\n",
      "        device,\n",
      "        scheduler,\n",
      "        n_examples\n",
      "):\n",
      "    model = model.train()\n",
      "\n",
      "    losses = []\n",
      "    correct_predictions = \u001b[34m0\u001b[39;49;00m\n",
      "\n",
      "    \u001b[34mfor\u001b[39;49;00m inputs, labels \u001b[35min\u001b[39;49;00m data_loader:\n",
      "        inputs = inputs.to(device)\n",
      "        labels = labels.to(device)\n",
      "\n",
      "        outputs = model(inputs)\n",
      "\n",
      "        _, preds = torch.max(outputs, dim=\u001b[34m1\u001b[39;49;00m)\n",
      "        loss = loss_fn(outputs, labels)\n",
      "\n",
      "        correct_predictions += torch.sum(preds == labels)\n",
      "        losses.append(loss.item())\n",
      "\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        optimizer.zero_grad()\n",
      "\n",
      "    scheduler.step()\n",
      "\n",
      "    \u001b[34mreturn\u001b[39;49;00m correct_predictions.double() / n_examples, np.mean(losses)\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32meval_model\u001b[39;49;00m(model, data_loader, loss_fn, device, n_examples):\n",
      "    model = model.eval()\n",
      "\n",
      "    losses = []\n",
      "    correct_predictions = \u001b[34m0\u001b[39;49;00m\n",
      "\n",
      "    \u001b[34mwith\u001b[39;49;00m torch.no_grad():\n",
      "        \u001b[34mfor\u001b[39;49;00m inputs, labels \u001b[35min\u001b[39;49;00m data_loader:\n",
      "            inputs = inputs.to(device)\n",
      "            labels = labels.to(device)\n",
      "\n",
      "            outputs = model(inputs)\n",
      "\n",
      "            _, preds = torch.max(outputs, dim=\u001b[34m1\u001b[39;49;00m)\n",
      "\n",
      "            loss = loss_fn(outputs, labels)\n",
      "\n",
      "            correct_predictions += torch.sum(preds == labels)\n",
      "            losses.append(loss.item())\n",
      "\n",
      "    \u001b[34mreturn\u001b[39;49;00m correct_predictions.double() / n_examples, np.mean(losses)\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtrain_model\u001b[39;49;00m(model, data_loaders, dataset_sizes, device,model_dir,n_epochs=\u001b[34m10\u001b[39;49;00m):\n",
      "    optimizer = optim.SGD(model.parameters(), lr=\u001b[34m0.001\u001b[39;49;00m, momentum=\u001b[34m0.9\u001b[39;49;00m)\n",
      "    scheduler = lr_scheduler.StepLR(optimizer, step_size=\u001b[34m7\u001b[39;49;00m, gamma=\u001b[34m0.1\u001b[39;49;00m)\n",
      "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
      "\n",
      "    history = defaultdict(\u001b[36mlist\u001b[39;49;00m)\n",
      "    best_accuracy = \u001b[34m0\u001b[39;49;00m\n",
      "\n",
      "    \u001b[34mfor\u001b[39;49;00m epoch \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(n_epochs):\n",
      "\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mEpoch \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mepoch + \u001b[34m1\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mn_epochs\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33m-\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m * \u001b[34m10\u001b[39;49;00m)\n",
      "\n",
      "        train_acc, train_loss = train_epoch(\n",
      "            model,\n",
      "            data_loaders[\u001b[33m'\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\n",
      "            loss_fn,\n",
      "            optimizer,\n",
      "            device,\n",
      "            scheduler,\n",
      "            dataset_sizes[\u001b[33m'\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\n",
      "        )\n",
      "\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mTrain loss \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mtrain_loss\u001b[33m}\u001b[39;49;00m\u001b[33m accuracy \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mtrain_acc\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "\n",
      "        val_acc, val_loss = eval_model(\n",
      "            model,\n",
      "            data_loaders[\u001b[33m'\u001b[39;49;00m\u001b[33mtest\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\n",
      "            loss_fn,\n",
      "            device,\n",
      "            dataset_sizes[\u001b[33m'\u001b[39;49;00m\u001b[33mtest\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\n",
      "        )\n",
      "\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mVal loss \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mval_loss\u001b[33m}\u001b[39;49;00m\u001b[33m accuracy \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mval_acc\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "        \u001b[36mprint\u001b[39;49;00m()\n",
      "\n",
      "        history[\u001b[33m'\u001b[39;49;00m\u001b[33mtrain_acc\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m].append(train_acc)\n",
      "        history[\u001b[33m'\u001b[39;49;00m\u001b[33mtrain_loss\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m].append(train_loss)\n",
      "        history[\u001b[33m'\u001b[39;49;00m\u001b[33mval_acc\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m].append(val_acc)\n",
      "        history[\u001b[33m'\u001b[39;49;00m\u001b[33mval_loss\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m].append(val_loss)\n",
      "\n",
      "        \u001b[34mif\u001b[39;49;00m val_acc > best_accuracy:\n",
      "            \u001b[36mprint\u001b[39;49;00m(os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "            torch.save(model.state_dict(), os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "            best_accuracy = val_acc\n",
      "\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mBest val accuracy: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mbest_accuracy\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "\n",
      "\u001b[37m#     model.load_state_dict(torch.load('best_model_state.bin'))\u001b[39;49;00m\n",
      "\n",
      "    \u001b[34mreturn\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_parse_args\u001b[39;49;00m():\n",
      "    \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\n",
      "\n",
      "    parser = argparse.ArgumentParser()\n",
      "\n",
      "    \u001b[37m# Data, model, and output directories\u001b[39;49;00m\n",
      "    \u001b[37m# model_dir is always passed in from SageMaker. By default this is a S3 path under the default bucket.\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model_dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--sm-model-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--train\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAINING\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--hosts\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mlist\u001b[39;49;00m, default=json.loads(os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_HOSTS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)))\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--current-host\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CURRENT_HOST\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "\n",
      "    \u001b[34mreturn\u001b[39;49;00m parser.parse_known_args()\n",
      "\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m==\u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
      "\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mstarting in main\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    args, unknown = _parse_args()\n",
      "\n",
      "    DATA_DIR = args.train\n",
      "\n",
      "    mean_nums = [\u001b[34m0.485\u001b[39;49;00m, \u001b[34m0.456\u001b[39;49;00m, \u001b[34m0.406\u001b[39;49;00m]\n",
      "    std_nums = [\u001b[34m0.229\u001b[39;49;00m, \u001b[34m0.224\u001b[39;49;00m, \u001b[34m0.225\u001b[39;49;00m]\n",
      "\n",
      "    transforms = {\u001b[33m'\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: T.Compose([\n",
      "        T.RandomResizedCrop(size=\u001b[34m256\u001b[39;49;00m),\n",
      "        T.RandomRotation(degrees=\u001b[34m15\u001b[39;49;00m),\n",
      "        T.RandomHorizontalFlip(),\n",
      "        T.ToTensor(),\n",
      "        T.Normalize(mean_nums, std_nums)\n",
      "    ]), \u001b[33m'\u001b[39;49;00m\u001b[33mtest\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: T.Compose([\n",
      "        T.Resize(size=\u001b[34m256\u001b[39;49;00m),\n",
      "        T.CenterCrop(size=\u001b[34m224\u001b[39;49;00m),\n",
      "        T.ToTensor(),\n",
      "        T.Normalize(mean_nums, std_nums)\n",
      "    ]),\n",
      "    }\n",
      "\n",
      "\n",
      "    DATASETS = [\u001b[33m'\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mtest\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\n",
      "\n",
      "    image_datasets = {d: ImageFolder(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mDATA_DIR\u001b[33m}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{\u001b[39;49;00md\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, transforms[d]) \u001b[34mfor\u001b[39;49;00m d \u001b[35min\u001b[39;49;00m DATASETS}\n",
      "\n",
      "    dataset_sizes = {d: \u001b[36mlen\u001b[39;49;00m(image_datasets[d]) \u001b[34mfor\u001b[39;49;00m d \u001b[35min\u001b[39;49;00m DATASETS}\n",
      "    class_names = image_datasets[\u001b[33m'\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m].classes\n",
      "\n",
      "    data_loaders = {d: DataLoader(image_datasets[d], batch_size=\u001b[34m8\u001b[39;49;00m, shuffle=\u001b[34mTrue\u001b[39;49;00m, num_workers=\u001b[34m4\u001b[39;49;00m) \u001b[34mfor\u001b[39;49;00m d \u001b[35min\u001b[39;49;00m DATASETS}\n",
      "\n",
      "    base_model = create_model(\u001b[36mlen\u001b[39;49;00m(class_names))\n",
      "\n",
      "    train_model(base_model, data_loaders, dataset_sizes, device, model_dir=args.model_dir)\n",
      "\n",
      "\n",
      "    \u001b[37m## Save model\u001b[39;49;00m\n",
      "/bin/sh: --: invalid option\n",
      "Usage:\t/bin/sh [GNU long option] [option] ...\n",
      "\t/bin/sh [GNU long option] [option] script-file ...\n",
      "GNU long options:\n",
      "\t--debug\n",
      "\t--debugger\n",
      "\t--dump-po-strings\n",
      "\t--dump-strings\n",
      "\t--help\n",
      "\t--init-file\n",
      "\t--login\n",
      "\t--noediting\n",
      "\t--noprofile\n",
      "\t--norc\n",
      "\t--posix\n",
      "\t--protected\n",
      "\t--rcfile\n",
      "\t--rpm-requires\n",
      "\t--restricted\n",
      "\t--verbose\n",
      "\t--version\n",
      "Shell options:\n",
      "\t-irsD or -c command or -O shopt_option\t\t(invocation only)\n",
      "\t-abefhkmnptuvxBCHP or -o option\n"
     ]
    }
   ],
   "source": [
    "!pygmentize ptModelCode.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Run training\n",
    "Now we call the estimators fit method with the URI location of the training data to start the training (runs approx 20 mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(training_data_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can call the model_data method on the estimator to find the location of the trained model artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 5. Deploying a model & review code\n",
    "Once trained, deploying a model is a simple call.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mrequests\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mPIL\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Image\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorchvision\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m transforms\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorchvision\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m models\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnn\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mio\u001b[39;49;00m\n",
      "\n",
      "logger = logging.getLogger(\u001b[31m__name__\u001b[39;49;00m)\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\n",
      "\n",
      "    n_classes=\u001b[34m3\u001b[39;49;00m\n",
      "\n",
      "    device = torch.device(\u001b[33m'\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m'\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    logger.info(\u001b[33m'\u001b[39;49;00m\u001b[33mLoading the model.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    model = models.resnet34(pretrained=\u001b[34mTrue\u001b[39;49;00m)\n",
      "\n",
      "    n_features = model.fc.in_features\n",
      "    model.fc = nn.Linear(n_features, n_classes)\n",
      "\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), \u001b[33m'\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\n",
      "        model.load_state_dict(torch.load(f,map_location=torch.device(\u001b[33m'\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)))\n",
      "\n",
      "    model.to(device).eval()\n",
      "    logger.info(\u001b[33m'\u001b[39;49;00m\u001b[33mDone loading model\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \u001b[34mreturn\u001b[39;49;00m model\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32minput_fn\u001b[39;49;00m(image_data, content_type=\u001b[33m'\u001b[39;49;00m\u001b[33mapplication/x-image\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m):\n",
      "    logger.info(\u001b[33m'\u001b[39;49;00m\u001b[33mDeserializing the input data.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \u001b[34mtry\u001b[39;49;00m:\n",
      "        \u001b[34mif\u001b[39;49;00m content_type == \u001b[33m'\u001b[39;49;00m\u001b[33mapplication/x-image\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            image_data = Image.open(io.BytesIO(image_data))\n",
      "            image_data=  image_data.convert(\u001b[33m'\u001b[39;49;00m\u001b[33mRGB\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \u001b[37m#         image_data = Image.open(requests.get(url, stream=True).raw)\u001b[39;49;00m\n",
      "    \u001b[37m# def input_fn(image_data):\u001b[39;49;00m\n",
      "    \u001b[37m#     logger.info('Deserializing the input data.')\u001b[39;49;00m\n",
      "    \u001b[37m#     image_data=image_data\u001b[39;49;00m\n",
      "\n",
      "            image_transform = transforms.Compose([\n",
      "                transforms.Resize(size=\u001b[34m256\u001b[39;49;00m),\n",
      "                transforms.CenterCrop(size=\u001b[34m224\u001b[39;49;00m),\n",
      "                transforms.ToTensor(),\n",
      "                transforms.Normalize([\u001b[34m0.485\u001b[39;49;00m, \u001b[34m0.456\u001b[39;49;00m, \u001b[34m0.406\u001b[39;49;00m], [\u001b[34m0.229\u001b[39;49;00m, \u001b[34m0.224\u001b[39;49;00m, \u001b[34m0.225\u001b[39;49;00m])\n",
      "            ])\n",
      "\n",
      "            \u001b[34mreturn\u001b[39;49;00m image_transform(image_data)\n",
      "\n",
      "        \u001b[34mraise\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mRequested unsupported ContentType in content_type: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcontent_type\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \u001b[34mexcept\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m e:\n",
      "        logger.info(\u001b[33m\"\u001b[39;49;00m\u001b[33msomething is wrong\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mpredict_fn\u001b[39;49;00m(input_data, model):\n",
      "    logger.info(\u001b[33m'\u001b[39;49;00m\u001b[33mGenerating prediction based on input parameters.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \u001b[34mif\u001b[39;49;00m torch.cuda.is_available():\n",
      "        input_data = input_data.view(\u001b[34m1\u001b[39;49;00m, \u001b[34m3\u001b[39;49;00m, \u001b[34m224\u001b[39;49;00m, \u001b[34m224\u001b[39;49;00m).cuda()\n",
      "    \u001b[34melse\u001b[39;49;00m:\n",
      "        input_data = input_data.view(\u001b[34m1\u001b[39;49;00m, \u001b[34m3\u001b[39;49;00m, \u001b[34m224\u001b[39;49;00m, \u001b[34m224\u001b[39;49;00m)\n",
      "    \u001b[34mwith\u001b[39;49;00m torch.no_grad():\n",
      "        model.eval()\n",
      "        out = model(input_data)\n",
      "        ps = torch.exp(out)\n",
      "    \u001b[34mreturn\u001b[39;49;00m ps\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32moutput_fn\u001b[39;49;00m(prediction_output, accept=\u001b[33m'\u001b[39;49;00m\u001b[33mapplication/json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m):\n",
      "    logger.info(\u001b[33m'\u001b[39;49;00m\u001b[33mSerializing the generated output.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    classes = {\u001b[34m0\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mPriority\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[34m1\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mRoundabout\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[34m2\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mSignal\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m}\n",
      "\n",
      "    topk, topclass = prediction_output.topk(\u001b[34m1\u001b[39;49;00m, dim=\u001b[34m1\u001b[39;49;00m)\n",
      "    result = []\n",
      "\n",
      "    \u001b[34mfor\u001b[39;49;00m i \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(\u001b[34m1\u001b[39;49;00m):\n",
      "        pred = {\u001b[33m'\u001b[39;49;00m\u001b[33mprediction\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: classes[topclass.cpu().numpy()[\u001b[34m0\u001b[39;49;00m][i]], \u001b[33m'\u001b[39;49;00m\u001b[33mscore\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mtopk.cpu().numpy()[\u001b[34m0\u001b[39;49;00m][i] * \u001b[34m100\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m}\n",
      "        logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mAdding prediction: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpred\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "        result.append(pred)\n",
      "\n",
      "    \u001b[34mif\u001b[39;49;00m accept == \u001b[33m'\u001b[39;49;00m\u001b[33mapplication/json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "        \u001b[34mreturn\u001b[39;49;00m json.dumps(result), accept\n",
      "    \u001b[34mraise\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mRequested unsupported ContentType in Accept: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00maccept\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "/bin/sh: --: invalid option\n",
      "Usage:\t/bin/sh [GNU long option] [option] ...\n",
      "\t/bin/sh [GNU long option] [option] script-file ...\n",
      "GNU long options:\n",
      "\t--debug\n",
      "\t--debugger\n",
      "\t--dump-po-strings\n",
      "\t--dump-strings\n",
      "\t--help\n",
      "\t--init-file\n",
      "\t--login\n",
      "\t--noediting\n",
      "\t--noprofile\n",
      "\t--norc\n",
      "\t--posix\n",
      "\t--protected\n",
      "\t--rcfile\n",
      "\t--rpm-requires\n",
      "\t--restricted\n",
      "\t--verbose\n",
      "\t--version\n",
      "Shell options:\n",
      "\t-irsD or -c command or -O shopt_option\t\t(invocation only)\n",
      "\t-abefhkmnptuvxBCHP or -o option\n"
     ]
    }
   ],
   "source": [
    "!pygmentize ptInfCode.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorchModel\n",
    "pytorch_model = PyTorchModel(model_data=estimator.model_data, \n",
    "                             role=role, \n",
    "                             entry_point='ptInfCode.py', \n",
    "                             framework_version='1.7',\n",
    "                             py_version='py3')\n",
    "predictor = pytorch_model.deploy(instance_type='ml.m5.4xlarge', initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets get the endpoint name from predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictor.endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 6. Test using an image\n",
    "Now that our endpoint is up and running, lets test it with an image and see how well it does\n",
    "In the cell below, replace the **'your_endpoint_name'** with the your endpoint name you had printed out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import json\n",
    "im_name=\"../data/test/Signal/S2.png\"\n",
    "\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName=predictor.endpoint_name,\n",
    "    ContentType='application/x-image',\n",
    "    Body=open(im_name, 'rb').read())\n",
    "\n",
    "# Now let us view the JSON response\n",
    "print(\"Now let us view the JSON response\" + str(json.loads(response['Body'].read().decode(\"utf-8\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the endpoint\n",
    "client = boto3.client('sagemaker')\n",
    "client.delete_endpoint(EndpointName=predictor.endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
