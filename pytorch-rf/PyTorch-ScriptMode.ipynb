{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Bring your own Script workshop\n",
    "\n",
    "Goal: In this notebook we will go through and run a PyTorch model to classify the junctions as priority, signal and roundabout as seen in data prep.\n",
    "\n",
    "Note Use conda_pytorch_p36 framework\n",
    "\n",
    "The outline of this notebook is\n",
    "\n",
    "1. Update to the latest SageMaker version & import libraries\n",
    "2. Download data, setup buckets and Understanding the data\n",
    "3. Setup estimator and review the AWS provided PyTorch container and provide our script to it.\n",
    "4. Run training.\n",
    "5. Deploy model to end point.\n",
    "6. Test using an image in couple of possible ways\n",
    "7. Clean up - delete the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "### 1. Update Sagemaker so we can access the latest containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/home/ec2-user/anaconda3/envs/pytorch_latest_p36/bin/python -m pip install --upgrade pip\n",
    "#!/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip\n",
    "!pip install -U sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will import the libraries and set up the initial variables we will be using in this lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "ON_SAGEMAKER_NOTEBOOK = True\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "if ON_SAGEMAKER_NOTEBOOK:\n",
    "    role = sagemaker.get_execution_role()\n",
    "else:\n",
    "    role = \"[YOUR ROLE]\"\n",
    "\n",
    "import boto3\n",
    "client = boto3.client('sagemaker-runtime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2. Next Download the data and setup bucket\n",
    "In the cell below, replace **\"your-unique-bucket-name\"** with the name of bucket you created in the data-prep notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give a globally unique bucket name\n",
    "my_bucket = \"your-unique-bucket-name\"\n",
    "!aws s3 mb 's3://'$my_bucket --region us-east-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the training bucket  \n",
    "training_data_uri=\"s3://{}\".format(my_bucket)\n",
    "training_data_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### copy these unzip images into source bucket so you avoid three steps above and safe time.\n",
    "!aws s3 sync s3://dc-summit-workshop-2021/scriptmode-byoc-wkshp-data/images/ $training_data_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy three sample images data from S3 bucket to local folder\n",
    "!aws s3 cp 's3://'$my_bucket/train/Priority/12481.png ../data/train/Priority/12481.png\n",
    "!aws s3 cp 's3://'$my_bucket/train/Roundabout/53408.png ../data/train/Roundabout/53408.png\n",
    "!aws s3 cp 's3://'$my_bucket/train/Signal/27258.png ../data/train/Signal/27258.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's view the dataset - three different images\n",
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "f, axs = plt.subplots(1,3,figsize=(15,15))\n",
    "img1 = mpimg.imread('../data/train/Priority/12481.png')\n",
    "img2 = mpimg.imread('../data/train/Roundabout/53408.png')\n",
    "img3 = mpimg.imread('../data/train/Signal/27258.png')\n",
    "\n",
    "axs[0].imshow(img1)\n",
    "axs[0].set_title(\"Priority\")\n",
    "axs[1].imshow(img2)\n",
    "axs[1].set_title(\"Roundabout\")\n",
    "axs[2].imshow(img3)\n",
    "axs[2].set_title(\"Signal\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### 3. PyTorch Estimator & review code\n",
    "\n",
    "Setup the estimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = PyTorch(entry_point='./script/ptModelCode.py',\n",
    "                    role=role,\n",
    "                    framework_version='1.8',\n",
    "                    instance_count=1,\n",
    "                    instance_type='ml.p2.xlarge',\n",
    "                    py_version='py3',\n",
    "                    # available hyperparameters: emsize, nhid, nlayers, lr, clip, epochs, batch_size,\n",
    "                    #                            bptt, dropout, tied, seed, log_interval\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Run training\n",
    "Launching a training job with the Python SDK.\n",
    "\n",
    "Now we call the estimators fit method with the URI location of the training data to start the training (runs approx 20 mins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "estimator.fit(training_data_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can call the model_data method on the estimator to find the location of the trained model artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 5. Deploying a model & review code\n",
    "Once trained, deploying a model is a simple call.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "pytorch_model = PyTorchModel(model_data=estimator.model_data, \n",
    "                             role=role, \n",
    "                             entry_point='./script/ptInfCode.py', \n",
    "                             framework_version='1.7',\n",
    "                             py_version='py3')\n",
    "\n",
    "predictor = pytorch_model.deploy(instance_type='ml.m5.4xlarge', initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets get the endpoint name from predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictor.endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy a test image to local disk\n",
    "!aws s3 cp 's3://'$my_bucket/test/Roundabout/R1.png ../data/test/Roundabout/R1.png\n",
    "!aws s3 cp 's3://'$my_bucket/test/Signal/S1.png ../data/test/Signal/S1.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 6. Test using an image\n",
    "Now that our endpoint is up and running, lets test it with an image and see how well it does\n",
    "In the cell below, replace the **'your_endpoint_name'** with the your endpoint name you had printed out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import json\n",
    "im_name=\"../data/test/Roundabout/R1.png\"\n",
    "#im_name=\"../data/test/Signal/S1.png\"\n",
    "\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName=predictor.endpoint_name,\n",
    "    ContentType='application/x-image',\n",
    "    Body=open(im_name, 'rb').read())\n",
    "\n",
    "# Now let us view the JSON response\n",
    "print(\"Now let us view the JSON response\" + str(json.loads(response['Body'].read().decode(\"utf-8\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate the predictions\n",
    "f, axs = plt.subplots(1,2,figsize=(15,15))\n",
    "img1 = mpimg.imread('../data/test/Roundabout/R1.png')\n",
    "img2 = mpimg.imread('../data/test/Signal/S1.png')\n",
    "axs[0].imshow(img1)\n",
    "axs[1].imshow(img2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the endpoint\n",
    "client = boto3.client('sagemaker')\n",
    "client.delete_endpoint(EndpointName=predictor.endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
